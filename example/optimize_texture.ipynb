{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Texture\n",
    "\n",
    "Optimize object's texture color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install and import requirements\n",
    "\n",
    "* torch_psdr: core library\n",
    "* pytorch (cuda): core dependency library\n",
    "* pywavefront: read `.obj` format mesh object\n",
    "* imageio: read image-based texture\n",
    "* matplotlib: show rendered image in notebook\n",
    "\n",
    "⚠️ ATTENTION:\n",
    "\n",
    "**Please restart notebook kernel after installation!**\n",
    "\n",
    "**DO NOT run following installation script if you have installed!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch_psdr is in channel luling. This will install cuda based pytorch automatically\n",
    "! conda install -y torch_psdr -c luling -c pytorch\n",
    "# install other dependencies we need to run this example\n",
    "! conda install -y imageio matplotlab -c conda-forge\n",
    "# install forked pywavefront\n",
    "! conda install pywavefront_uv -c luling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch_psdr as dr\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "import torch.optim\n",
    "import torch.nn.functional as F\n",
    "from pywavefront_uv import Wavefront\n",
    "import imageio.v3 as imageio\n",
    "from utilities import translate, scale, rotate\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# define some global variables\n",
    "device = \"cuda:0\"\n",
    "tex_H, tex_W = 512, 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read mesh objects\n",
    "\n",
    "Define functions to load scene objects and an object named `spot` with image-based texture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_obj(obj_path):\n",
    "  scene = Wavefront(obj_path, create_materials=True, collect_faces=True)\n",
    "  vertices = torch.tensor(scene.vertices, dtype=torch.float32, device=device)\n",
    "  uvs = None if scene.parser.tex_coords == [] else torch.tensor(scene.parser.tex_coords, dtype=torch.float32, device=device)\n",
    "  objs = {}\n",
    "  for name, mesh in scene.meshes.items():\n",
    "    if name is None:\n",
    "      name = str(hash(mesh))\n",
    "    indices = torch.tensor(mesh.faces, dtype=torch.int32, device=device)\n",
    "    face_indices = indices[:,:,0]\n",
    "    uv_indices = indices[:,:,1] if indices[0,0,1] != -1 else None\n",
    "    material = mesh.materials[0]\n",
    "    obj = None\n",
    "    if name == \"light\":\n",
    "      emit = torch.tensor(material.ambient[:3], dtype=torch.float32, device=device)\n",
    "      obj = dr.AreaLight(vertices, face_indices, emit)\n",
    "    else:\n",
    "      diffuse = torch.tensor(material.diffuse[:3], dtype=torch.float32, device=device)\n",
    "      normal = None\n",
    "      roughness = torch.tensor([0.5], dtype=torch.float32, device=device)\n",
    "      material = dr.DiffuseBsdfMaterial(diffuse, roughness, normal)\n",
    "      obj = dr.Mesh(vertices, uvs, face_indices, uv_indices, material)\n",
    "    objs[name] = obj\n",
    "  return objs\n",
    "\n",
    "def load_spot(obj_path, diffuse_tex=None, rotate_angle=None):\n",
    "  scene = Wavefront(obj_path, create_materials=True, collect_faces=True)\n",
    "  vertices = torch.tensor(scene.vertices, dtype=torch.float32, device=device)\n",
    "  if rotate_angle is not None:\n",
    "    pitch, yaw, roll = rotate_angle\n",
    "    vertices = rotate(vertices, pitch, yaw, roll)\n",
    "  vertices.mul_(150).add_(300)\n",
    "  uvs = None if scene.parser.tex_coords == [] else torch.tensor(scene.parser.tex_coords, dtype=torch.float32, device=device)\n",
    "  objs = {}\n",
    "  for name, mesh in scene.meshes.items():\n",
    "    if name is None:\n",
    "      name = str(hash(mesh))\n",
    "    indices = torch.tensor(mesh.faces, dtype=torch.int32, device=device)\n",
    "    face_indices = indices[:,:,0]\n",
    "    uv_indices = indices[:,:,1] if indices[0,0,1] != -1 else None\n",
    "    material = mesh.materials[0]\n",
    "    if diffuse_tex is None:\n",
    "      tex = imageio.imread(material.texture.path)\n",
    "      diffuse_tex = torch.tensor(tex, dtype=torch.float32, device=device) / 255\n",
    "    normal = None\n",
    "    roughness = torch.tensor([1], dtype=torch.float32, device=device)\n",
    "    material = dr.DiffuseBsdfMaterial(diffuse_tex, roughness, normal)\n",
    "    obj = dr.Mesh(vertices, uvs, face_indices, uv_indices, material)\n",
    "  objs[name] = obj\n",
    "  return objs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_camera():\n",
    "  look_from = torch.tensor([278, 278, -800], dtype=torch.float32, device=device)\n",
    "  look_at = torch.tensor([278, 278, 0], dtype=torch.float32, device=device)\n",
    "  up = torch.tensor([0, 1, 0], dtype=torch.float32, device=device)\n",
    "  vfov = torch.tensor([torch.deg2rad(torch.tensor(38.0))], dtype=torch.float32, device=device)\n",
    "  height, width = 600, 600\n",
    "  camera = dr.PerspectiveCamera(\n",
    "    look_from = look_from,\n",
    "    look_at = look_at,\n",
    "    up = up,\n",
    "    vfov = vfov,\n",
    "    height = height,\n",
    "    width = width,\n",
    "  )\n",
    "  return camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_img(scene, diff_mode=False):\n",
    "  integrator = dr.PathIntegrator(\n",
    "    n_pass=1,\n",
    "    spp_interior=12,\n",
    "    enable_light_visable=False,\n",
    "    spp_primary_edge=1,\n",
    "    spp_secondary_edge=1,\n",
    "    primary_edge_preprocess_rounds=1,\n",
    "    secondary_edge_preprocess_rounds=1,\n",
    "    max_bounce=3,\n",
    "    mis_light_samples=2,\n",
    "    mis_bsdf_samples=0,\n",
    "  )\n",
    "  imgs = integrator.renderD(scene) if diff_mode else integrator.renderC(scene)\n",
    "  return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimize texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all\n",
    "def render_once(obj_path, spot_path, diffuse_tex=None, spot_rotation=None, diff_mode=False):\n",
    "  objs = load_obj(obj_path)\n",
    "  spot = load_spot(spot_path, diffuse_tex, spot_rotation)\n",
    "  objs.update(spot)\n",
    "\n",
    "  lights = [obj for name, obj in objs.items() if name == \"light\"]\n",
    "  meshes = [obj for name, obj in objs.items() if name != \"light\"]\n",
    "\n",
    "  cameras = [set_camera()]\n",
    "\n",
    "  scene = dr.Scene(cameras, meshes, lights)\n",
    "\n",
    "  imgs = render_img(scene, diff_mode)\n",
    "\n",
    "  return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# render target image\n",
    "obj_path = \"../data/input/cornell_box.obj\"\n",
    "spot_path = \"../data/input/spot/spot_triangulated.obj\"\n",
    "target_imgs = render_once(obj_path, spot_path)\n",
    "target_img = target_imgs[0]\n",
    "tgt_img = target_img.detach().cpu().numpy()\n",
    "plt.imshow(tgt_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set texture parameters to optimize\n",
    "tex_param = torch.zeros((tex_H, tex_W, 3), dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "# set optimizer\n",
    "optim = torch.optim.SGD([tex_param], lr=1e8)\n",
    "\n",
    "# optimize texture parameters\n",
    "for iter in range(5):\n",
    "  tex = torch.sigmoid(tex_param)\n",
    "  imgs = render_once(obj_path, spot_path, tex, diff_mode=True)\n",
    "  img = imgs[0]\n",
    "  loss = F.mse_loss(img, target_img)\n",
    "  loss.backward()\n",
    "  optim.step()\n",
    "\n",
    "  clear_output(wait=False)\n",
    "  print(f\"iter: {iter}; avg grad: {torch.mean(tex_param.grad)}; loss: {loss}\")\n",
    "  img_np = img.detach().cpu().numpy()\n",
    "  plt.imshow(img_np)\n",
    "  plt.show()\n",
    "\n",
    "  optim.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view target uv texture and optimized texture\n",
    "target_diffuse_tex_path = \"../data/input/spot/spot_texture.png\"\n",
    "target_diffuse_tex = imageio.imread(target_diffuse_tex_path)\n",
    "plt.imshow(target_diffuse_tex)\n",
    "plt.show()\n",
    "\n",
    "optimized_tex = tex_param.detach().cpu().numpy()\n",
    "plt.imshow(optimized_tex)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimize whole texture from multiple random view directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tex_param = torch.zeros((tex_H, tex_W, 3), dtype=torch.float32, device=device, requires_grad=True)\n",
    "optim = torch.optim.SGD([tex_param], lr=1e7)\n",
    "iterations = 40\n",
    "for iter in range(iterations):\n",
    "  pitch, yaw, roll = random.random() * 2 * math.pi, random.random() * 2 * math.pi, random.random() * math.pi\n",
    "  # render target image with specified orientation\n",
    "  target_imgs = render_once(obj_path, spot_path, diffuse_tex=None, spot_rotation=(pitch, yaw, roll), diff_mode=False)\n",
    "  # render image with texture parameters\n",
    "  tex = torch.sigmoid(tex_param)\n",
    "  imgs = render_once(obj_path, spot_path, tex, (pitch, yaw, roll), diff_mode=True)\n",
    "  loss = F.mse_loss(imgs[0], target_imgs[0])\n",
    "  # compute grads, implicitly accumulate texture parameter grads\n",
    "  loss.backward()\n",
    "\n",
    "  print(f\"iter: {iter}; avg grad: {torch.mean(tex_param.grad)}; loss: {loss}\")\n",
    "\n",
    "  clear_output(wait=False)\n",
    "  optim.step()\n",
    "  optim.zero_grad()  \n",
    "  tex = torch.sigmoid(tex_param).detach().cpu().numpy()\n",
    "  plt.imshow(tex)\n",
    "  plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psdr-run",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75f4d79b5265e7e4841cd4401730c162c1fd53010a91a0fa006e7b6ed4e5f2a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
